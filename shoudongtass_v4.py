import requests
import csv
import re
import time
import random
from bs4 import BeautifulSoup
from urllib.parse import quote

# --- é…ç½® ---
INPUT_FILE = "urls.txt"
OUTPUT_FILE = "huawei_corpus_final.csv"
# æ¶µç›–æ‰€æœ‰ç¿»è¯‘å¯èƒ½ï¼Œç¡®ä¿åŒ¹é…ä¸æ¼
KEYWORDS = ["Huawei", "åä¸º", "Ğ¥ÑƒĞ°Ğ²ÑĞ¹", "Hua wei"]

# å¤‡é€‰ User-Agent æ± ï¼Œæ¯æ¬¡é‡è¯•æ›´æ¢èº«ä»½
UA_POOL = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
]

def get_with_retry(url):
    """é‡åˆ° 429 ä¸æ”¾å¼ƒï¼Œæ­»ç£•åˆ°åº•ç›´åˆ°æ‹¿åˆ°å†…å®¹"""
    encoded_url = quote(url, safe='')
    # è®¾ä¸ºç¿»è¯‘æˆè‹±æ–‡ (tl=en)ï¼Œå› ä¸ºè‹±æ–‡åˆ†å¥æ›´å‡†ï¼Œä¸”å¯¹åŸå§‹å…³é”®è¯ä¿ç•™æœ€å¥½
    translate_url = f"https://translate.google.com/translate?sl=auto&tl=en&u={encoded_url}"
    
    retry_count = 0
    max_retries = 5 # å•ç¯‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé˜²æ­¢æ­»å¾ªç¯
    
    while retry_count < max_retries:
        headers = {
            'User-Agent': random.choice(UA_POOL),
            'Referer': 'https://www.google.com/',
        }
        
        try:
            # åŸºç¡€å»¶è¿Ÿï¼š5-10ç§’
            wait_time = random.uniform(6, 10) + (retry_count * 20) # è¶Šé”™ç­‰è¶Šä¹…
            if retry_count > 0:
                print(f"\nâ³ ç¬¬ {retry_count} æ¬¡é‡è¯•ï¼Œæ­£åœ¨ä¼‘çœ  {int(wait_time)} ç§’...")
            time.sleep(wait_time)
            
            response = requests.get(translate_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«æ­£å¸¸çš„ç¿»è¯‘æ¡†æ¶ï¼Œé˜²æ­¢æ‹¿åˆ°ç©ºçš„ 200 é¡µé¢
                if "google-src-active" in response.text or "result-container" in response.text or len(response.text) > 5000:
                    return response.text
                else:
                    print("âš ï¸  é¡µé¢åŠ è½½ä¸å…¨ï¼Œå‡†å¤‡é‡è¯•...")
            
            if response.status_code == 429:
                print("ğŸ›‘ è§¦å‘ 429 é™åˆ¶ï¼ŒGoogle æ­£åœ¨èµ¶äºº...")
                retry_count += 1
                continue
            
            # å…¶ä»–é”™è¯¯ç ä¹Ÿé‡è¯•
            retry_count += 1
            
        except Exception as e:
            print(f"âŒ ç½‘ç»œå¼‚å¸¸: {e}")
            retry_count += 1
            
    return None

def extract_sentences(html):
    if not html: return []
    
    soup = BeautifulSoup(html, 'html.parser')
    # æå–æ‰€æœ‰æ–‡æœ¬å—
    for script in soup(["script", "style"]):
        script.extract()
        
    # è·å–å…¨æ–‡å¹¶æŒ‰ç…§å¤šè¯­ç§æ ‡ç‚¹åˆ†å¥
    text = soup.get_text(" ", strip=True)
    sentences = re.split(r'(?<=[ã€‚ï¼Ÿï¼.!?])\s*', text)
    
    matches = []
    for s in sentences:
        s_clean = s.strip()
        # åªè¦å‘½ä¸­ä»»ä½•ä¸€ä¸ªå…³é”®è¯å°±ä¿ç•™
        if any(kw.lower() in s_clean.lower() for kw in KEYWORDS):
            if 15 < len(s_clean) < 500:
                matches.append(s_clean)
    
    return list(set(matches))

def main():
    print("ğŸ”¥ å¯åŠ¨â€˜æ­»ç£•é‡è¯•â€™æ¨¡å¼ã€‚ç›®æ ‡ï¼šè¯­æ–™å®Œæ•´æå–ã€‚")
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8-sig', newline='') as f_out:
        writer = csv.writer(f_out)
        writer.writerow(['åºå·', 'é“¾æ¥', 'æ ‡é¢˜', 'åŒ¹é…è¯­æ–™'])

        with open(INPUT_FILE, 'r', encoding='utf-8') as f_in:
            lines = [l.strip() for l in f_in.readlines() if ',' in l]

        count = 1
        for i, line in enumerate(lines):
            title, url = line.split(',', 1)
            if "https://" in url[8:]: url = "https://" + url.split("https://")[-1]

            print(f"[{i+1}/{len(lines)}] å¤„ç†: {title[:20]}...", end=" ", flush=True)
            
            html_content = get_with_retry(url)
            sentences = extract_sentences(html_content)
            
            if sentences:
                for s in sentences:
                    writer.writerow([count, url, title, s])
                    count += 1
                print(f"âœ… æˆåŠŸæ‹¿å› {len(sentences)} æ¡")
                f_out.flush() # æ¯ä¸€ç¯‡éƒ½å¼ºåˆ¶ä¿å­˜ä¸€æ¬¡ï¼Œé˜²æ–­ç”µ
            else:
                print("â“ ä¾ç„¶æœªåŒ¹é… (å¯èƒ½è¯¥æ–‡ç¡®å®æ— å…³é”®è¯)")

    print(f"\nâœ¨ ä»»åŠ¡å½»åº•å®Œæˆï¼ç»“æœå·²å­˜å…¥ {OUTPUT_FILE}")

if __name__ == "__main__":
    main()